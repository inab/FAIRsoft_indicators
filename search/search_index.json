{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to FAIRsoft Indicators!","text":"<p>The FAIRsoft indicators are designed to automatically measure the FAIRness (Findability, Accessibility, Interoperability, and Reusability) of research software. By leveraging these indicators, developers and stakeholders can greatly enhance the impact and sustainability of their software projects.</p> <p>Explore the indicators in depth and learn how to integrate them into your software initiatives in the Indicators section.</p>"},{"location":"#our-indicators-are-evolving","title":"Our Indicators are Evolving! \ud83d\udcc8","text":"<p>We are committed to continuously enhancing and broadening our collection of software quality indicators. Community contributions play a pivotal role in this process. Your insights, suggestions, and active involvement are crucial to our collective success. </p> <p>Check out our Contributing Guidelines to get started!</p>"},{"location":"#quick-links","title":"Quick Links","text":"<p>\ud83d\ude80 Navigate Easily:</p> <ul> <li>GitHub Repository: Dive into our codebase, contribute to the project, or star the repository to show your support!</li> <li>About the Project: Understand the ambitions, objectives, and the people behind our initiatives.</li> </ul> <p>\ud83d\udcc4 Discover More:</p> <ul> <li>Software Observatory: Discover how our project fits into the broader software ecosystem and learn about its significant impacts.</li> <li>Publication: Explore the academic research and real-world applications of our indicators.</li> </ul>"},{"location":"about/","title":"About Us","text":"<p>Welcome to our \"About Us\" page! Here, we provide information about our team and our affiliations.</p>"},{"location":"about/#our-team","title":"Our Team","text":"<p>We are a dedicated team of researchers and developers passionate about advancing the field of research software quality. Our team is based at the Barcelona Supercomputing Center (BSC), a leading research institution in high-performance computing and computational science.</p>"},{"location":"about/#openebench","title":"OpenEBench","text":"<p>We are proud to be part of the OpenEBench platform, a community-driven initiative aimed at promoting openness, transparency, and reproducibility in research. OpenEBench provides tools, resources, and guidelines to support researchers in benchmarking and evaluating their scientific software.</p>"},{"location":"about/#the-software-observatory","title":"The Software Observatory","text":"<p>As part of the OpenEBench platform, we are responsible for the Software Observatory, an initiative focused on monitoring and analyzing the landscape of research software. The Software Observatory aims to provide insights into the usage, impact, and evolution of research software across various domains and disciplines.</p>"},{"location":"about/#contact-us","title":"Contact Us","text":"<p>If you have any questions, feedback, or would like to collaborate with us, please feel free to reach out to our team:</p> <ul> <li>Email:</li> <li>GitHub:</li> </ul>"},{"location":"indicators/","title":"Indicators Structure","text":"<p>Welcome to the comprehensive guide on FAIRsoft indicators, designed to systematically assess the FAIRness of research software. Our indicators are split into two categories: high-level and low-level, each tailored to provide insights at different granularity levels.</p>"},{"location":"indicators/#high-level-indicators","title":"High-level Indicators","text":"<p>High-level indicators represent overarching aspects of FAIRness based on the FAIR principles, offering a broad evaluation of software adherence to these principles. These indicators are categorized by the specific FAIR principle they assess:</p> <ul> <li>F (Findability)</li> <li>A (Accessibility)</li> <li>I (Interoperability)</li> <li>R (Reusability)</li> </ul> <p>Each indicator is denoted by a letter representing the principle followed by a number indicating its position within that category, e.g., F3 for the third Findability indicator.</p>"},{"location":"indicators/#examples-of-high-level-indicators","title":"Examples of High-level Indicators","text":"<ul> <li>F3: Discoverability - Assessing the ease with which software can be found by both humans and machines.</li> <li>I1: Data Format Standards and Practices - Evaluating adherence to industry standards in data formatting.</li> <li>R1: Usage Documentation - Examining the availability and comprehensiveness of documentation.</li> </ul>"},{"location":"indicators/#low-level-indicators","title":"Low-level Indicators","text":"<p>Low-level indicators provide detailed, actionable criteria supporting the high-level indicators. These indicators delve deeper into specific aspects of FAIRness, enabling a thorough assessment process.</p> <p>Each low-level indicator is denoted by extending the high-level code with a sub-number, indicating its detailed focus under the broader category, e.g., F3.1 for the first detailed aspect under the third Findability indicator.</p>"},{"location":"indicators/#examples-of-low-level-indicators","title":"Examples of Low-level Indicators","text":"<ul> <li>F3.1: Discoverability in Software Registries</li> <li>F3.2: Discoverability in Software Repositories</li> <li>F3.3: Discoverability in Literature</li> </ul>"},{"location":"indicators/#applicability","title":"Applicability","text":"<p>The relevance of each indicator may vary depending on the software type\u2014whether it's \"web\" or \"non-web\": - Web software: Applications accessed through the web, such as online tools and APIs. - Non-web software: Applications run locally, like desktop apps and command-line tools.</p>"},{"location":"indicators/#examples-of-applicability","title":"Examples of Applicability","text":"<ul> <li>A1.1: Existence of an API or Web Interface - Applicable to Web.</li> <li>A1.2: Existence of Downloadable and Buildable Software Version - Applicable to Non-web.</li> <li>I1.1: Use of Standard Data Formats - Applicable to All.</li> </ul>"},{"location":"indicators/#scores-and-scoring-method","title":"Scores and Scoring Method","text":"<p>Indicators are scored on a scale from 0 to 1, with 1 representing optimal FAIRness. Each indicator's weight influences the overall FAIRness score, highlighting its importance in the comprehensive assessment.</p>"},{"location":"indicators/#scoring-insights","title":"Scoring Insights","text":"<p>Scores are instrumental in generating statistics that help evaluate the collective FAIRness of software portfolios, guiding improvements and strategic decision-making. Scores should be understood as a general indication of the software's FAIRness, rather than a definitive assessment</p>"},{"location":"indicators/#overview-of-indicators","title":"Overview of Indicators","text":"<p>The indicators are visualized in a structured diagram that illustrates the connection between high-level indicators and the underlying FAIR principles. The diagram also highlights the weights assigned to each indicator, underscoring their significance in the overall evaluation process.</p>"},{"location":"indicators/#key-points-in-the-overview-diagram","title":"Key Points in the Overview Diagram","text":"<ul> <li>Indicator Weights: Displayed on the connecting arrows in the diagram, influencing the total FAIRness score. The weights of the low-level indicators are not shown in the diagram.</li> <li>Implementation Status: Unimplemented indicators are shown in gray to indicate their development status.</li> <li>Software Type Applicability: Not all indicators apply universally; specific applicabilities are noted in the diagram legend.</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/","title":"A1.  Existence of an available working version","text":"<p>Whether it is possible to access/download/build a working version of the software.  </p> <p>Being able to access the software as a user is the central aspect of Accessibility.</p>"},{"location":"indicators/accessibility/A1_downloadable/#a11-existence-of-an-api-or-web-interface","title":"A1.1. Existence of an API or web interface","text":""},{"location":"indicators/accessibility/A1_downloadable/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether it is possible to access a working version of the software through an API or web interface.</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Providing an API or web interface allows remote access with just an internet connection, greatly enhancing the software's usability, facilitating integration with other systems, and enabling a broader range of users to benefit from its features without complex installations. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>A working URL is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>web</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#weight","title":"Weight","text":"<ul> <li>0.6</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#a12-existence-of-downloadable-and-buildable-software-working-version","title":"A1.2. Existence of downloadable and buildable software working version","text":""},{"location":"indicators/accessibility/A1_downloadable/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether it is possible to access/download/build a working version of the software including the generation of a software container. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>A downloadable and buildable version of the research software significantly increases its freedom of use and usability. It allows users to install and run the software where and as needed, e.g. to use locally and in/as modules. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>At least one download working link is considered valid.</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#weight_1","title":"Weight","text":"<ul> <li>0.5</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#a13-existence-of-installation-instructions","title":"A1.3. Existence of installation instructions","text":""},{"location":"indicators/accessibility/A1_downloadable/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether there is a set of instructions and other necessary information that the user can follow to build the software. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Clear installation instructions are essential for ensuring successful software setup, reducing installation and deployment time, minimising potential errors, and enhancing overall user experience.  </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>A link explicitly stated as installation instructions or manual, instructions on the web if Bioconductor package, and availability through Galaxy ToolShed are all considered valid.</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#weight_2","title":"Weight","text":"<ul> <li>0.2</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#a14-existence-of-test-data","title":"A1.4. Existence of test data","text":""},{"location":"indicators/accessibility/A1_downloadable/#what-is-being-measured_3","title":"What is being measured?","text":"<ul> <li>Whether test data is available. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#why-should-we-measure-it_3","title":"Why should we measure it?","text":"<ul> <li>Test data confirms the software's functionality and provides users with practical examples for setting up their own datasets, thereby increasing usability and ensuring robustness. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#how-do-we-measure-it_3","title":"How do we measure it?","text":"<ul> <li>At least one piece of test data is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#types-it-applies-to_3","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#weight_3","title":"Weight","text":"<ul> <li> <p>web: 0.4 </p> </li> <li> <p>non-web: 0.2</p> </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#a15-existence-of-software-source-code","title":"A1.5. Existence of software source code","text":""},{"location":"indicators/accessibility/A1_downloadable/#what-is-being-measured_4","title":"What is being measured?","text":"<ul> <li>Whether software source code is available.</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#why-should-we-measure-it_4","title":"Why should we measure it?","text":"<ul> <li>The availability of source code allows users to compile the software on various operating systems, address installation challenges, manage dependencies, and customise the code to meet specific needs, enhancing adaptability and user control. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#how-do-we-measure-it_4","title":"How do we measure it?","text":"<ul> <li>A link explicitly stated as source code is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#types-it-applies-to_4","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A1_downloadable/#weight_4","title":"Weight","text":"<ul> <li>0.2</li> </ul>"},{"location":"indicators/accessibility/A2_trackability/","title":"A2.  Software history trackability","text":"<p>Whether code and metadata are available even when the software is no longer in use. </p> <p>To match software provenance with analysed data provenance.</p>"},{"location":"indicators/accessibility/A2_trackability/#a21-existence-of-metadata-of-previous-versions-in-software-repositories","title":"A2.1. Existence of metadata of previous versions in software repositories","text":""},{"location":"indicators/accessibility/A2_trackability/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether there is available metadata of previous versions. </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Maintaining metadata for previous software versions in repositories ensures the traceability of changes and updates, offering insights into the evolution of the software and facilitating the understanding of its historical context and development. </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Not measured </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#weight","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#a22-existence-of-accessible-previous-versions-of-the-software","title":"A2.2. Existence of accessible previous versions of the software","text":""},{"location":"indicators/accessibility/A2_trackability/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether there are available previous versions. </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Accessibility to previous software versions allows users to reproduce analyses with a given software version. </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Not measured </li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/accessibility/A2_trackability/#weight_1","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/","title":"A3.  Unrestricted access","text":"<p>Whether the software lacks restrictions in terms of authorization and infrastructure/platform needed to use it. </p> <p>Unrestricted access removes entry barriers and ensures that a wider audience can use the software without facing restrictive conditions or platform limitations.</p> <p>Note</p> <p>Although low restrictions make software more accessible, there are still cases where restrictions may be necessary. For example, some software may be designed to be used to handle sensitive data, and thus, it may be necessary to restrict access to the software to authorized users. In other cases, the software may be designed to work with a specific infrastructure or platform for the sake of reliability and/or performance. </p>"},{"location":"indicators/accessibility/A3_unrestricted_access/#a31-no-registration-is-required","title":"A3.1. No Registration is required","text":""},{"location":"indicators/accessibility/A3_unrestricted_access/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether software can be used without registration </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Eliminating mandatory registration enhances accessibility by allowing users to access and utilise the software anonymously, removing potential privacy concerns and lowering entry barriers. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Not measured </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#weight","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#a32-availability-of-version-for-open-source-operating-system","title":"A3.2. Availability of version for open-source operating system","text":""},{"location":"indicators/accessibility/A3_unrestricted_access/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether the software can be used in a free operating system. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Providing software versions for open-source operating systems removes economic barriers, making research software accessible to a broader audience who may not have the resources for costly proprietary systems. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>GNU/Linux among the compatible operating systems is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#weight_1","title":"Weight","text":"<ul> <li>0.25</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#a33-availability-for-several-operating-systems","title":"A3.3. Availability for several operating systems","text":""},{"location":"indicators/accessibility/A3_unrestricted_access/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether there are versions of the software for several operative systems. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Supporting multiple operating systems makes the software more accessible to users with diverse needs, constraints, and preferences, especially in scenarios where specific hardware systems like clusters or supercomputers are required. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>The existence of software versions for at least two operating systems is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#weight_2","title":"Weight","text":"<ul> <li>0.25</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#a34-availability-through-publicly-available-e-infrastructures","title":"A3.4. Availability through publicly available e-Infrastructures","text":""},{"location":"indicators/accessibility/A3_unrestricted_access/#what-is-being-measured_3","title":"What is being measured?","text":"<ul> <li>Whether the software can be used through publicly available e-infrastructure. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#why-should-we-measure-it_3","title":"Why should we measure it?","text":"<ul> <li>Making software available on publicly available e-infrastructures removes significant barriers to use by providing computational resources accessible via a web browser, eliminating the need for local installation or infrastructure investment, thereby broadening accessibility to a wide range of users regardless of their technical or financial resources. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#how-do-we-measure-it_3","title":"How do we measure it?","text":"<ul> <li>A Galaxy public server or VRE (Virtual Research Environment) link is considered valid. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#types-it-applies-to_3","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#weight_3","title":"Weight","text":"<ul> <li>0.25</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#a35-availability-through-several-e-infrastructures","title":"A3.5. Availability through several e-Infrastructures","text":""},{"location":"indicators/accessibility/A3_unrestricted_access/#what-is-being-measured_4","title":"What is being measured?","text":"<ul> <li>Whether the software can be used in several e-infrastructure. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#why-should-we-measure-it_4","title":"Why should we measure it?","text":"<ul> <li>Users usually use e-infrastructures to build workflows. The e-infrastructure they choose to use, thus, depends on software being available in the same platform and other factors. The more e-infrastructures a software is available, the greater the likelihood a user will be able to use it. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#how-do-we-measure-it_4","title":"How do we measure it?","text":"<ul> <li>At least two Galaxy public server or VRE (Virtual Research Environment) links are considered valid. </li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#types-it-applies-to_4","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/accessibility/A3_unrestricted_access/#weight_4","title":"Weight","text":"<ul> <li>0.25</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/","title":"F1. Identity Uniqueness","text":"<p>Whether the software has a proper, unique and persistent identifier. </p> <p>The uniqueness of an identifier is necessary to unambiguously refer to that resource and that resource alone.</p>"},{"location":"indicators/findability/F1_identity_uniqueness/#f11-uniqueness-of-name","title":"F1.1. Uniqueness of name","text":""},{"location":"indicators/findability/F1_identity_uniqueness/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether the software has a unique name to identify it that sets it apart from others. </li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>The name is commonly used as the primary identifier of software. Each tool should have a unique name to avoid ambiguities. Different versions of the same software should share a name, but if substantial modifications are done, the identifier should change for the new piece of software.</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>A name is valid.</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#weight","title":"Weight","text":"<ul> <li>0.8</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#f12-identifiability-of-version","title":"F1.2. Identifiability of version","text":""},{"location":"indicators/findability/F1_identity_uniqueness/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether there is a scheme to uniquely and properly identify the software version.</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<p>A clear and consistent versioning scheme is crucial for distinguishing between different software releases, enabling precise communication and effective update management while also aiding in tracking incremental changes, thus ensuring that users can easily reference, use, and provide feedback on specific versions. </p>"},{"location":"indicators/findability/F1_identity_uniqueness/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<p>A version of the form X.X is considered valid.</p>"},{"location":"indicators/findability/F1_identity_uniqueness/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F1_identity_uniqueness/#weight_1","title":"Weight","text":"<ul> <li>0.2</li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/","title":"F2. Existence of Metadata","text":"<p>Whether the software is described with rich metadata, including scientific applicability. </p> <p>Metadata makes it possible to find tools through search engines and decide if they interest the user.</p>"},{"location":"indicators/findability/F2_existence_of_metadata/#f21-existence-of-structured-metadata","title":"F2.1. Existence of structured metadata","text":""},{"location":"indicators/findability/F2_existence_of_metadata/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether metadata is adjusted to specific metadata formats. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Using specific, structured metadata formats enhances machine readability, which not only increases the software's findability by search engines but also improves interoperability and facilitates the accurate extraction and utilisation of data, thereby boosting its usability and accessibility for both humans and machines. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Any source of structured metadata (e.g. JSON, XML, YAML) is considered valid. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#weight","title":"Weight","text":"<ul> <li>0.6</li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#f22-existence-of-standardised-metadata","title":"F2.2. Existence of standardised metadata","text":""},{"location":"indicators/findability/F2_existence_of_metadata/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether metadata is described using accepted ontologies. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Standardised metadata using consensual terminology simplifies the interpretation and automated processing of software descriptions by ensuring a uniform approach to information representation. This uniformity enhances search efficiency and accuracy, making finding software with specific features easier and faster. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Use of EDAM and/or Bioschemas to describe the software is considered valid. </li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F2_existence_of_metadata/#weight_1","title":"Weight","text":"<ul> <li>0.4</li> </ul>"},{"location":"indicators/findability/F3_searchability/","title":"F3.  Discoverability","text":"<p>How software can be found. There are multitude of mechanisms for scientists looking to find specific software</p> <p>(*) Scoring of high-level indicator F3 is based on the number of low-level indicators fulfilled: One fulfilled low-level indicator scores 0.7, two fulfilled indicators score 0.85, and fulfillment of all three indicators scores 1.0</p>"},{"location":"indicators/findability/F3_searchability/#f31-discoverability-in-software-registries","title":"F3.1. Discoverability in software registries","text":""},{"location":"indicators/findability/F3_searchability/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether software is included in the main software registries. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Software registries serve as primary resources for users seeking specific resources, and ensuring software is discoverable in these registries enhances visibility, facilitates peer recognition, and increases the potential for adoption and collaboration.</li> </ul>"},{"location":"indicators/findability/F3_searchability/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>At least one software registry among the metadata sources is considered valid. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all </li> </ul>"},{"location":"indicators/findability/F3_searchability/#weight","title":"Weight","text":"<ul> <li>(*)</li> </ul>"},{"location":"indicators/findability/F3_searchability/#f32-discoverability-in-software-repositories","title":"F3.2. Discoverability in software repositories","text":""},{"location":"indicators/findability/F3_searchability/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether software can be found in any of the major software repositories. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Users can use software repositories as additional resources when looking for research software. Listing software in repositories such as GitHub and GitLab enhances its visibility and accessibility, making it easier for scientists to find, use, and contribute to software development. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<p>An associated software repository (GitHub, GitLab or Bitbucket) is considered valid. </p>"},{"location":"indicators/findability/F3_searchability/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F3_searchability/#weight_1","title":"Weight","text":"<ul> <li>(*)</li> </ul>"},{"location":"indicators/findability/F3_searchability/#f33-discoverability-in-the-scientific-literature","title":"F3.3. Discoverability in the scientific literature","text":""},{"location":"indicators/findability/F3_searchability/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether software can be found in specialised literature services. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Specialised scientific literature serves as a crucial reference for finding software, particularly new ones, as it not only enhances visibility and credibility but also provides detailed context and validation through citations and reviews, including the ones by peers. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>At least one associated publication is considered valid. </li> </ul>"},{"location":"indicators/findability/F3_searchability/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/findability/F3_searchability/#weight_2","title":"Weight","text":"<ul> <li>(*)</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/","title":"I1. Data Format Standards and Practices","text":"<p>Whether the software adheres to data format standards and its operational practices concerning data handling it encompasses standard formats and APIs, the flexibility and verifiability of these formats, and the tracking of data provenance. </p> <p>Adhering to data format standards and robust data handling practices is critical for ensuring interoperability and reliability across systems, enhancing software integration, maintaining data integrity, and supporting traceability, which boosts user trust and system efficiency.</p>"},{"location":"indicators/interoperability/I1_input_output/#i11-use-of-standard-data-formats","title":"I1.1. Use of standard data formats","text":""},{"location":"indicators/interoperability/I1_input_output/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether the input and output data types are formally specified and related to accepted ontologies. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Using standard data formats minimises the need for error-prone and resource-intensive transformations to meet unique software input requirements. It facilitates collective efforts to develop high-quality data management tools, reducing reliance on ad hoc data transformations. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>At least one input or output data format specified in the EDAM format ontology is considered valid. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#weight","title":"Weight","text":"<ul> <li>0.5</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#i12-use-of-standard-api-specification-framework","title":"I1.2. Use of standard API specification framework","text":""},{"location":"indicators/interoperability/I1_input_output/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether APIs (REST, libraries) are documented in a standard framework. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Documenting APIs in a standard framework ensures they are universally understandable and easily integrable across different platforms and services. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Not measured.</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>web</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#weight_1","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#i13-verifiability-of-data-formats","title":"I1.3 Verifiability of data formats","text":""},{"location":"indicators/interoperability/I1_input_output/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether input/output data are specified using verifiable schemas. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Verifiability of data formats is crucial as it allows users to automatically confirm that their data complies with accepted standards, ensuring compatibility and readability by other systems using the same format. This verification reduces errors in data processing and enhances overall system interoperability. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>Any standard formats (I1.1) plus JSON, XML, RDF and XDS  are considered valid. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#weight_2","title":"Weight","text":"<ul> <li>0.3</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#i14-flexibility-of-data-format-supported","title":"I1.4. Flexibility of data format supported","text":""},{"location":"indicators/interoperability/I1_input_output/#what-is-being-measured_3","title":"What is being measured?","text":"<ul> <li>Whether the software allows one to choose among various input/output data formats or provides the necessary mechanisms to convert other standard formats into the supported ones. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#why-should-we-measure-it_3","title":"Why should we measure it?","text":"<ul> <li>Supporting various data formats directly in software eliminates the need for data transformations, thereby reducing error points and saving significant time and resources for users, enhancing flexibility and efficiency. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#how-do-we-measure-it_3","title":"How do we measure it?","text":"<ul> <li>At least two input or output data formats are valid. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#types-it-applies-to_3","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#weight_3","title":"Weight","text":"<ul> <li>0.2</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#i15-generation-of-provenance-information","title":"I1.5. Generation of provenance information","text":""},{"location":"indicators/interoperability/I1_input_output/#what-is-being-measured_4","title":"What is being measured?","text":"<ul> <li>Whether the software provides provenance information according to accepted standards. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#why-should-we-measure-it_4","title":"Why should we measure it?","text":"<ul> <li>Generating provenance information is crucial for adhering to the FAIR data principles, as it provides detailed documentation that enhances data transparency, traceability, and trustworthiness, thereby supporting improved data management. </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#how-do-we-measure-it_4","title":"How do we measure it?","text":"<ul> <li>Not measured </li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#types-it-applies-to_4","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I1_input_output/#weight_4","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/","title":"I2. Software Integration","text":"<p>Whether software can be easily integrated into workflows or used in connection with other software. </p> <p>Research software is usually used with other software as part of a workflow or any other composition. </p>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#i21-existence-of-apilibrary-version","title":"I2.1. Existence of API/library version","text":""},{"location":"indicators/interoperability/I2_workflow_compatibility/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether the software has an API/library version to be included in users' workflows. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Providing software as modular libraries or well-defined APIs is crucial for seamless integration into larger systems or workflows, ensuring compatibility and functionality across various platforms and environments. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>The type of the software registered either as library or API is considered valid. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#weight","title":"Weight","text":"<ul> <li>0.5</li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#i22-e-infrastructure-compatibility","title":"I2.2. E-infrastructure compatibility","text":""},{"location":"indicators/interoperability/I2_workflow_compatibility/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether the software can be deployed in e-infrastructures. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Compatibility with e-infrastructures is critical, as researchers and professionals extensively use these platforms to build data processing pipelines. If software cannot be deployed on these infrastructures, it risks being inaccessible to many potential users, limiting its utility and adoption in essential workflows. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Being one of the metadata sources, the availability of the software through the Galaxy Toolshed is considered valid. </li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I2_workflow_compatibility/#weight_1","title":"Weight","text":"<ul> <li>0.5</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/","title":"I3. Dependencies availability","text":"<p>Whether dependencies are documented and mechanisms to obtain them exist. </p> <p>Software dependencies are essential for it to function properly. </p>"},{"location":"indicators/interoperability/I3_dependencies_available/#i31-existence-of-dependencies-statement","title":"I3.1. Existence of Dependencies statement","text":""},{"location":"indicators/interoperability/I3_dependencies_available/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether the software includes details about dependencies.</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>A clear dependencies statement informs users about the additional software required to operate the main software effectively. This transparency helps ensure that all necessary components are installed, facilitating a smoother setup and experience. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>At least one dependency stated is valid. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#weight","title":"Weight","text":"<ul> <li>0.33</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#i32-availability-of-software-dependencies","title":"I3.2. Availability of software dependencies","text":""},{"location":"indicators/interoperability/I3_dependencies_available/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether the software includes its dependencies or mechanisms to access them. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Providing dependencies along with the software can significantly enhance user experience by minimising the steps needed for installation. This method helps to eliminate common setup obstacles, facilitating a more streamlined and error-free user experience. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Bioconductor, Bioconda, or Galaxy Europey among the metadata sources of the software is considered valid. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#weight_1","title":"Weight","text":"<ul> <li>0.33</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#i33-availability-through-dependencies-aware-systems","title":"I3.3. Availability through dependencies-aware systems","text":""},{"location":"indicators/interoperability/I3_dependencies_available/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether the software is distributed via a dependencies-aware system. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Ensuring software availability through dependencies-aware systems like package managers enhances accessibility and ease of installation. This feature allows users to efficiently manage software and its dependencies, improving reliability and reducing compatibility issues across different environments. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>Bioconductor, Bioconda, or Galaxy Europey among the metadata sources of the software is considered valid. </li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/interoperability/I3_dependencies_available/#weight_2","title":"Weight","text":"<ul> <li>0.33</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/","title":"R1. Existence of usage documentation","text":"<p>Whether software provides adequate usage documentation. </p> <p>Usage documentation such as tutorials, use guides, examples of user cases, and 'how to' allow users to properly and effectively use the software.</p>"},{"location":"indicators/reusability/R1_usage_documentation/#r11-existence-of-usage-guides","title":"R1.1 Existence of usage guides","text":""},{"location":"indicators/reusability/R1_usage_documentation/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether software user guides are provided.</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>User guides provide comprehensive information for users to understand and use the software. These guides help ensure users can fully exploit the software\u2019s capabilities, leading to better user experience and reduced support queries. </li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Any documentation except news, license and terms of use is considered valid.</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#weight","title":"Weight","text":"<ul> <li>1.0</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#r12-existence-of-usage-examples","title":"R1.2 Existence of usage examples","text":""},{"location":"indicators/reusability/R1_usage_documentation/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether examples of use cases are provided. </li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Usage examples demonstrate practical applications of the software, providing detailed clarity that complements the broader information in user guides and enhances overall understanding. </li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Not measured. </li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R1_usage_documentation/#weight_1","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/reusability/R2_license/","title":"R2. Existence of license and/or terms of use","text":"<p>Whether a clear and accessible usage license is provided.</p> <p>Explicit licenses or terms of use are necessary to provide a clear framework for the use of any research software. The lack of a license or terms of use and installation can prevent users, especially from industry and regulated sectors, from installing, executing and using software.</p>"},{"location":"indicators/reusability/R2_license/#r21-existence-of-terms-of-use","title":"R2.1. Existence of terms of use","text":""},{"location":"indicators/reusability/R2_license/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether terms of use are stated. </li> </ul>"},{"location":"indicators/reusability/R2_license/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Clearly stated terms of use ensure that users are fully aware of the conditions and limitations of software usage before its adoption, promoting transparency and informed decision-making. </li> </ul>"},{"location":"indicators/reusability/R2_license/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Terms of use or license are considered valid. </li> </ul>"},{"location":"indicators/reusability/R2_license/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>web</li> </ul>"},{"location":"indicators/reusability/R2_license/#weight","title":"Weight","text":"<ul> <li>1.0</li> </ul>"},{"location":"indicators/reusability/R2_license/#r22-existence-of-conditions-of-use","title":"R2.2. Existence of conditions of use","text":""},{"location":"indicators/reusability/R2_license/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether conditions of installation and use are stated. </li> </ul>"},{"location":"indicators/reusability/R2_license/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>The existence of clearly defined conditions of use is essential, as it ensures users understand and agree to the terms under which software can be utilised before they begin using it, fostering transparency and compliance. </li> </ul>"},{"location":"indicators/reusability/R2_license/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Conditions of use or license are considered valid. </li> </ul>"},{"location":"indicators/reusability/R2_license/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>non-web</li> </ul>"},{"location":"indicators/reusability/R2_license/#weight_1","title":"Weight","text":"<ul> <li>1.0</li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/","title":"R3. Existence of Contribution Recognition and Governance","text":"<p>Whether there are policies governing contributor roles and systems in place for acknowledging their contributions ensuring fair and transparent collaboration within software projects. </p> <p>Clear policies and guidelines on contributing to a software project attract and empower external developers, fostering a collaborative environment.</p>"},{"location":"indicators/reusability/R3_contribution_policy/#r31-existence-of-the-contributors-policy","title":"R3.1. Existence of the Contributors policy","text":""},{"location":"indicators/reusability/R3_contribution_policy/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether a document stating the contributor's policy exists. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>A specified contributors policy is crucial because it provides external developers with the necessary guidelines for contributing, facilitating their involvement and enhancing the software's development and improvement. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>Not measured. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#weight","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#r32existence-of-credit","title":"R3.2.Existence of credit","text":""},{"location":"indicators/reusability/R3_contribution_policy/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether credit for contributions is provided. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>Credit is essential as it acknowledges contributors' intellectual property rights and ensures their contributions are appropriately recognised under existing regulations and towards the overall research community. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Authors are considered valid. </li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R3_contribution_policy/#weight_1","title":"Weight","text":"<ul> <li>1.0</li> </ul>"},{"location":"indicators/reusability/R4_provenance/","title":"R4. Existence of Versioning and Historical Traceability","text":"<p>How effectively the software manages version control and documents historical changes, ensuring clear updates traceability and consistency in release practices for enhanced reliability, sustainability and auditability. </p> <p>Explicit version control and documented historical changes facilitate efficient maintenance and debugging, enhance regulatory compliance, and build trust among users and developers by promoting transparency and accountability in the software's evolution.</p>"},{"location":"indicators/reusability/R4_provenance/#r41-use-of-version-control","title":"R4.1. Use of version control","text":""},{"location":"indicators/reusability/R4_provenance/#what-is-being-measured","title":"What is being measured?","text":"<ul> <li>Whether the software follows a version-control system. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#why-should-we-measure-it","title":"Why should we measure it?","text":"<ul> <li>Using version control is crucial as it systematically records and tracks changes to the software, making it easier to manage updates and trace modifications over time. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#how-do-we-measure-it","title":"How do we measure it?","text":"<ul> <li>A software repository hosted in GitHub, Bitbucket or GitLab is considered valid. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#types-it-applies-to","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R4_provenance/#weight","title":"Weight","text":"<ul> <li>1.0</li> </ul>"},{"location":"indicators/reusability/R4_provenance/#r42-existence-of-a-release-policy","title":"R4.2. Existence of a release policy","text":""},{"location":"indicators/reusability/R4_provenance/#what-is-being-measured_1","title":"What is being measured?","text":"<ul> <li>Whether the software follows a defined and documented release policy. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#why-should-we-measure-it_1","title":"Why should we measure it?","text":"<ul> <li>A clear release policy is essential because it informs users about the changes and improvements between software versions, enabling them to understand updates and make informed decisions about upgrades. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#how-do-we-measure-it_1","title":"How do we measure it?","text":"<ul> <li>Not measured. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#types-it-applies-to_1","title":"Types it applies to","text":"<ul> <li>all</li> </ul>"},{"location":"indicators/reusability/R4_provenance/#weight_1","title":"Weight","text":"<ul> <li>0.0</li> </ul>"},{"location":"indicators/reusability/R4_provenance/#r43-existence-of-metadata-of-previous-versions-in-software-repositories","title":"R4.3. Existence of metadata of previous versions in software repositories","text":""},{"location":"indicators/reusability/R4_provenance/#what-is-being-measured_2","title":"What is being measured?","text":"<ul> <li>Whether there is available metadata of previous versions. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#why-should-we-measure-it_2","title":"Why should we measure it?","text":"<ul> <li>Maintaining metadata of previous versions in software repositories is crucial because it ensures users can verify the existence and specifics of past software versions, particularly those referenced in published research, thereby providing essential context and supporting reproducibility. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#how-do-we-measure-it_2","title":"How do we measure it?","text":"<ul> <li>Not measured. </li> </ul>"},{"location":"indicators/reusability/R4_provenance/#types-it-applies-to_2","title":"Types it applies to","text":"<ul> <li>all</li> </ul> <p>### Weight </p> <ul> <li>0.0</li> </ul>"},{"location":"introduction/CONTRIBUTING/","title":"How to Contribute to Our Collection of Research Software Quality Indicators","text":"<p>Thank you for your interest in contributing to our collection of research software quality indicators! Your involvement is vital for enhancing the comprehensiveness and effectiveness of our indicators. Below you will find detailed ways you can contribute to the project.</p>"},{"location":"introduction/CONTRIBUTING/#accessing-the-github-repository","title":"Accessing the GitHub Repository","text":"<p>Our project is hosted on GitHub. If you're reading this guide on our website and would like to contribute directly, please visit the FAIRsoft Research Quality Indicators Repository.</p>"},{"location":"introduction/CONTRIBUTING/#contribution-guidelines","title":"Contribution Guidelines","text":""},{"location":"introduction/CONTRIBUTING/#1-familiarize-yourself-with-the-project","title":"1. Familiarize Yourself with the Project","text":"<p>Start by understanding the scope and objectives of our project: </p> <ul> <li> <p>Review the documentation where the indicators are described.</p> </li> <li> <p>Understand the existing indicators, their importance, and how they are used.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#2-explore-existing-issues","title":"2. Explore Existing Issues","text":"<p>Look through the project's issue tracker to find ongoing discussions, requests for enhancements, or reports of bugs: </p> <ul> <li> <p>Identify areas where you can contribute or propose new ideas. </p> </li> <li> <p>Issues might include suggestions for new indicators, refinements of existing ones, or technical improvements.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#3-submit-a-new-issue","title":"3. Submit a New Issue","text":"<p>If you identify a potential improvement or have a new indicator in mind:  </p> <ul> <li> <p>Submit a new issue detailing your idea. </p> </li> <li> <p>Provide comprehensive details including the purpose of the indicator, its measurement methodology, and any relevant literature or examples.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#4-participate-in-discussions","title":"4. Participate in Discussions","text":"<p>Engage actively in the discussions section: </p> <ul> <li> <p>Share your insights, provide feedback, and help refine proposals. </p> </li> <li> <p>Discussions are great platforms for brainstorming and collaborating on new ideas.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#5-propose-changes-via-pull-requests","title":"5. Propose Changes via Pull Requests","text":"<p>If you're familiar with GitHub and Git: </p> <ul> <li> <p>Fork the repository, create a new branch for your changes, and develop your enhancements. </p> </li> <li> <p>Submit a pull request with a clear description of your changes and reference any related issue(s). </p> </li> <li> <p>Follow any coding standards and guidelines provided in the repository.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#6-review-contributions","title":"6. Review Contributions","text":"<p>Participate in the review process by providing constructive feedback on other contributors' pull requests.</p>"},{"location":"introduction/CONTRIBUTING/#7-spread-the-word","title":"7. Spread the Word","text":"<p>Help expand our community: </p> <ul> <li> <p>Share the project within your networks. </p> </li> <li> <p>Present the indicators at workshops, seminars, and conferences. </p> </li> <li> <p>Encourage your peers to contribute.</p> </li> </ul>"},{"location":"introduction/CONTRIBUTING/#stay-connected","title":"Stay Connected","text":"<p>Follow the repository to stay updated on new discussions, issues, and updates. Your ongoing engagement is crucial for the project's success.</p> <p>Thank you for being a part of our community and contributing to the advancement of research software quality indicators!</p>"}]}